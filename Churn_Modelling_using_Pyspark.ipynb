{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d58d661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries will be imported were ever necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7800b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71498224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating basic Saprk session\n",
    "spark=SparkSession.builder.appName('churn_modelling').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1fb2669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle dataset link : https://www.kaggle.com/shrutimechlearn/churn-modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4e3b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|RowNumber|CustomerId|Surname |CreditScore|Geography|Gender|Age|Tenure|Balance |NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|1        |15634602  |Hargrave|619        |France   |Female|42 |2     |0.0     |1            |1        |1             |101348.88      |1     |\n",
      "|2        |15647311  |Hill    |608        |Spain    |Female|41 |1     |83807.86|1            |0        |1             |112542.58      |0     |\n",
      "+---------+----------+--------+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv('D://M. Tech in Data Science & Machine Learning//Big Data Analytics//Sem_Prep//Churn_Modelling//Churn_Modelling.csv', header=True,inferSchema=True)\n",
    "df.show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a5a64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()#total records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73aae9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)#total length of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcfd1264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RowNumber: integer (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Surname: string (nullable = true)\n",
      " |-- CreditScore: integer (nullable = true)\n",
      " |-- Geography: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tenure: integer (nullable = true)\n",
      " |-- Balance: double (nullable = true)\n",
      " |-- NumOfProducts: integer (nullable = true)\n",
      " |-- HasCrCard: integer (nullable = true)\n",
      " |-- IsActiveMember: integer (nullable = true)\n",
      " |-- EstimatedSalary: double (nullable = true)\n",
      " |-- Exited: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()#column summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97571d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column Name: RowNumber   column datatype: int\n",
      "column Name: CustomerId   column datatype: int\n",
      "column Name: Surname   column datatype: string\n",
      "column Name: CreditScore   column datatype: int\n",
      "column Name: Geography   column datatype: string\n",
      "column Name: Gender   column datatype: string\n",
      "column Name: Age   column datatype: int\n",
      "column Name: Tenure   column datatype: int\n",
      "column Name: Balance   column datatype: double\n",
      "column Name: NumOfProducts   column datatype: int\n",
      "column Name: HasCrCard   column datatype: int\n",
      "column Name: IsActiveMember   column datatype: int\n",
      "column Name: EstimatedSalary   column datatype: double\n",
      "column Name: Exited   column datatype: int\n"
     ]
    }
   ],
   "source": [
    "for i, t in df.dtypes:#column and its datatypes\n",
    "    print('column Name:', i, ' ','column datatype:',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340dcc7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age        Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  10000.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800      5.012800   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806      2.892174   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000      0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000      3.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000      5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000      7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000     10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().describe()#stastical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49a1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, count, col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f026a3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
      "|RowNumber|CustomerId|Surname|CreditScore|Geography|Gender|Age|Tenure|Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+---------+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
      "|        0|         0|      0|          0|        0|     0|  0|     0|      0|            0|        0|             0|              0|     0|\n",
      "+---------+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking for null values\n",
    "df.select([count(when(isnan(c) | col(c).isNull(),c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26eb1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are no null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c431174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RowNumber',\n",
       " 'CustomerId',\n",
       " 'Surname',\n",
       " 'CreditScore',\n",
       " 'Geography',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'Exited']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d09590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('RowNumber','CustomerId','Surname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6e00377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bucketizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6043d526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|Age|count|\n",
      "+---+-----+\n",
      "| 31|  404|\n",
      "| 85|    1|\n",
      "| 65|   18|\n",
      "| 53|   74|\n",
      "| 78|    5|\n",
      "| 34|  447|\n",
      "| 81|    4|\n",
      "| 28|  273|\n",
      "| 76|   11|\n",
      "| 27|  209|\n",
      "| 26|  200|\n",
      "| 44|  257|\n",
      "| 22|   84|\n",
      "| 47|  175|\n",
      "| 52|  102|\n",
      "| 40|  432|\n",
      "| 20|   40|\n",
      "| 57|   75|\n",
      "| 54|   84|\n",
      "| 48|  168|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ed3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(Age)|\n",
      "+--------+\n",
      "|      92|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Age':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a228da3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(Age)|\n",
      "+--------+\n",
      "|      18|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.agg({'Age':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6fd8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age groups are between 18 and 92, we use age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af0699ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a1e5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "split=[18,30,50,70,92]\n",
    "bucketizer=Bucketizer(splits=split,inputCol='Age',outputCol='Age_group')\n",
    "df1=bucketizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "febe57c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Age_group|count|\n",
      "+---------+-----+\n",
      "|      0.0| 1641|\n",
      "|      1.0| 6964|\n",
      "|      3.0|  151|\n",
      "|      2.0| 1244|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupby('Age_group').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5572be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#String Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9374f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column Name: Geography   column datatype: string\n",
      "column Name: Gender   column datatype: string\n"
     ]
    }
   ],
   "source": [
    "Indexers=[]\n",
    "for i, t in df.dtypes:#column and its datatypes\n",
    "    if t=='string':\n",
    "        print('column Name:', i, ' ','column datatype:',t)\n",
    "        Indexers.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d05f8ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography', 'Gender']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d3e06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06ddfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexing=StringIndexer(inputCols=['Geography', 'Gender','Exited'],\n",
    "                  outputCols=['Geography_index', 'Gender_index','label'])\n",
    "df2=indexing.fit(df1).transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d4938ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+------+--------+-------------+---------+--------------+---------------+---------+---------------+------------+-----+\n",
      "|CreditScore|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Age_group|Geography_index|Gender_index|label|\n",
      "+-----------+---+------+--------+-------------+---------+--------------+---------------+---------+---------------+------------+-----+\n",
      "|        619| 42|     2|     0.0|            1|        1|             1|      101348.88|      1.0|            0.0|         1.0|  1.0|\n",
      "|        608| 41|     1|83807.86|            1|        0|             1|      112542.58|      1.0|            2.0|         1.0|  0.0|\n",
      "+-----------+---+------+--------+-------------+---------+--------------+---------------+---------+---------------+------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df2.drop('Geography', 'Gender','Exited')\n",
    "df2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d568dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 7963|\n",
      "|  1.0| 2037|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupby('label').count().show()#reanmed the colum from Exited to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "059dbd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27a3ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6554325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'Age_group',\n",
       " 'Geography_index',\n",
       " 'Gender_index',\n",
       " 'label']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cef245f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=['CreditScore','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','Age_group','Geography_index','Gender_index'], outputCol='features')\n",
    "df3=assembler.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67bc42c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+-----+\n",
      "|features                                                   |label|\n",
      "+-----------------------------------------------------------+-----+\n",
      "|[619.0,42.0,2.0,0.0,1.0,1.0,1.0,101348.88,1.0,0.0,1.0]     |1.0  |\n",
      "|[608.0,41.0,1.0,83807.86,1.0,0.0,1.0,112542.58,1.0,2.0,1.0]|0.0  |\n",
      "|[502.0,42.0,8.0,159660.8,3.0,1.0,0.0,113931.57,1.0,0.0,1.0]|1.0  |\n",
      "+-----------------------------------------------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select('features','label').show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7e3657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48498433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "763ff8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_indexer=VectorIndexer(inputCol='features', outputCol='indexed_features')\n",
    "df4=vector_indexer.fit(df3).transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbdd7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|            features|    indexed_features|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|[619.0,42.0,2.0,0...|[619.0,42.0,2.0,0...|  1.0|\n",
      "|[608.0,41.0,1.0,8...|[608.0,41.0,1.0,8...|  0.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select('features','indexed_features','label').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45de5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c24d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1 = df4.randomSplit([0.70, 0.30], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42dd02ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7049, 2951)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.count(),test1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "06a3cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4c65b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c52fce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70b5e542",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(featuresCol='features',labelCol='label')\n",
    "lr_model=lr.fit(train1)\n",
    "lr_model_summary=lr_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "868c6734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8043694141012909\n",
      "Precision: 0.766111004227326\n",
      "Recall: 0.8043694141012909\n",
      "F1 Score: 0.7599154444511099\n",
      "Area under the curve : 0.7591301059796025\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',lr_model_summary.accuracy)\n",
    "print('Precision:',lr_model_summary.weightedPrecision)\n",
    "print('Recall:',lr_model_summary.weightedRecall)\n",
    "print('F1 Score:',lr_model_summary.weightedFMeasure())\n",
    "print('Area under the curve :',lr_model_summary.areaUnderROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7559526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ce22062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37f07bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier(featuresCol='indexed_features', labelCol='label')\n",
    "dt_model=dt.fit(train1)\n",
    "dt_prediction=dt_model.transform(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41c340a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CreditScore',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'Age_group',\n",
       " 'Geography_index',\n",
       " 'Gender_index',\n",
       " 'label',\n",
       " 'features',\n",
       " 'indexed_features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_prediction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf9f8065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------------------------+----------+-----+\n",
      "|rawPrediction|probability                             |prediction|label|\n",
      "+-------------+----------------------------------------+----------+-----+\n",
      "|[17.0,173.0] |[0.08947368421052632,0.9105263157894737]|1.0       |1.0  |\n",
      "|[6.0,61.0]   |[0.08955223880597014,0.9104477611940298]|1.0       |1.0  |\n",
      "+-------------+----------------------------------------+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_prediction.select('rawPrediction','probability','prediction','label').show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3a69e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe44dce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8505591324974585\n",
      "f1: 0.8365268722205028\n",
      "Precision: 0.8395040430562379\n",
      "Recall: 0.8505591324974585\n",
      "Area under the ROC curve =  0.8365268722205028\n"
     ]
    }
   ],
   "source": [
    "evaluator=MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='label')\n",
    "print('Accuracy:',evaluator.evaluate(dt_prediction, {evaluator.metricName: \"accuracy\"}))\n",
    "print('f1:',evaluator.evaluate(dt_prediction, {evaluator.metricName: \"f1\"}))\n",
    "print('Precision:',evaluator.evaluate(dt_prediction, {evaluator.metricName: \"weightedPrecision\"}))\n",
    "print('Recall:',evaluator.evaluate(dt_prediction, {evaluator.metricName: \"weightedRecall\"}))\n",
    "print('Area under the ROC curve = ',evaluator.evaluate(dt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc8b9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76aa3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bcc818a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol='indexed_features',labelCol='label')\n",
    "rf_model= rf.fit(train1)\n",
    "rf_prediction = rf_model.transform(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54f0222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+---------------------------------------+----------+-----+\n",
      "|rawPrediction                         |probability                            |prediction|label|\n",
      "+--------------------------------------+---------------------------------------+----------+-----+\n",
      "|[7.692143325657921,12.30785667434208] |[0.38460716628289604,0.615392833717104]|1.0       |1.0  |\n",
      "|[6.818034242892532,13.181965757107468]|[0.3409017121446266,0.6590982878553734]|1.0       |1.0  |\n",
      "+--------------------------------------+---------------------------------------+----------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_prediction.select('rawPrediction','probability','prediction','label').show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea41932a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8542866824805151\n",
      "f1: 0.8300452843906327\n",
      "Precision: 0.8543755642029085\n",
      "Recall: 0.8542866824805151\n",
      "Area under the ROC curve =  0.8300452843906327\n"
     ]
    }
   ],
   "source": [
    "evaluator=MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='label')\n",
    "print('Accuracy:',evaluator.evaluate(rf_prediction, {evaluator.metricName: \"accuracy\"}))\n",
    "print('f1:',evaluator.evaluate(rf_prediction, {evaluator.metricName: \"f1\"}))\n",
    "print('Precision:',evaluator.evaluate(rf_prediction, {evaluator.metricName: \"weightedPrecision\"}))\n",
    "print('Recall:',evaluator.evaluate(rf_prediction, {evaluator.metricName: \"weightedRecall\"}))\n",
    "print('Area under the ROC curve = ',evaluator.evaluate(rf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ab25178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "012d3947",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2, test2 =df.randomSplit([0.7,0.3],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b883505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb3e407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline=Pipeline(stages = [bucketizer,indexing,assembler,lr])\n",
    "lr_pipeline_model=lr_pipeline.fit(train2)\n",
    "lr_pipeline_prediciton=lr_pipeline_model.transform(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c3191aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8085394781430024\n",
      "f1: 0.7655328517940844\n",
      "Precision: 0.7794328086348744\n",
      "Recall: 0.8085394781430024\n",
      "Area under the ROC curve =  0.8300452843906327\n"
     ]
    }
   ],
   "source": [
    "evaluator=MulticlassClassificationEvaluator(predictionCol='prediction',labelCol='label')\n",
    "print('Accuracy:',evaluator.evaluate(lr_pipeline_prediciton, {evaluator.metricName: \"accuracy\"}))\n",
    "print('f1:',evaluator.evaluate(lr_pipeline_prediciton, {evaluator.metricName: \"f1\"}))\n",
    "print('Precision:',evaluator.evaluate(lr_pipeline_prediciton, {evaluator.metricName: \"weightedPrecision\"}))\n",
    "print('Recall:',evaluator.evaluate(lr_pipeline_prediciton, {evaluator.metricName: \"weightedRecall\"}))\n",
    "print('Area under the ROC curve = ',evaluator.evaluate(rf_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8de19f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------END--------------------------------------------#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
